{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment_5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "92rIk_DQCe8C"
      },
      "source": [
        "#importing the necessary libraries\n",
        "import pandas as pd\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.chrome.options import Options \n",
        "import time\n",
        "from bs4 import BeautifulSoup\n",
        "import lxml\n",
        "from requests_html import HTMLSession\n",
        "\n",
        "chrome_options = Options()\n",
        "chrome_options.add_extension('ad_block.crx')\n",
        "\n",
        "# driver = webdriver.Chrome(options=chrome_options)\n",
        "driver = webdriver.Chrome()\n",
        "\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1)'\n",
        "}\n",
        "\n",
        "def exno():\n",
        "\twindow_before = driver.window_handles[1]\n",
        "\tdriver.switch_to.window(window_before)\n",
        "\tdriver.close()\n",
        "\twindow_before = driver.window_handles[0]\n",
        "\tdriver.switch_to.window(window_before)\n",
        "\n",
        "\n",
        "#1)\n",
        "\n",
        "Rank = []\n",
        "Name = []\n",
        "Artist = []\n",
        "Upload_date = []\n",
        "View = []\n",
        "\n",
        "def youtuve():\n",
        "\tdriver.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos/')\n",
        "\n",
        "\t# exno()\n",
        "\n",
        "\tcor = driver.find_element_by_xpath('//a[@class=\"external text\"]')\n",
        "\tcor.click()\n",
        "\n",
        "\ttime.sleep(5)\n",
        "\n",
        "\tser = driver.find_element_by_xpath('//div[@class=\"mw-search-result-heading\"]')\n",
        "\tser.click()\n",
        "\n",
        "\ttime.sleep(5)\n",
        "\n",
        "\thtml = driver.page_source\n",
        "\tsoup = BeautifulSoup(html, 'lxml')\n",
        "\ttable = soup.find('table', class_=\"wikitable\")\n",
        "\tt = table.find('tbody')\n",
        "\titems = t.find_all('td')\n",
        "\n",
        "\tfor i in range(0,180,6):\n",
        "\t\tRank.append(items[i].text)\n",
        "\n",
        "\tfor i in range(1,180,6):\n",
        "\t\tName.append(items[i].text)\n",
        "\n",
        "\tfor i in range(2,180,6):\n",
        "\t\tArtist.append(items[i].text)\n",
        "\n",
        "\tfor i in range(3,180,6):\n",
        "\t\tView.append(items[i].text)\n",
        "\t\n",
        "\tfor i in range(4,180,6):\n",
        "\t\tUpload_date.append(items[i].text)\n",
        "\n",
        "\tdf = pd.DataFrame({})\n",
        "\tdf['Rank'] = Rank\n",
        "\tdf['Name'] = Name \n",
        "\tdf['Artist'] = Artist\n",
        "\tdf['View'] = View\n",
        "\tdf['Upload_date'] = Upload_date\n",
        "\tdf.to_csv('youtube top views')\n",
        "\ttime.sleep(10)\n",
        "\tdriver.quit()\n",
        "\n",
        "\n",
        "youtuve()\n",
        "\n",
        "\n",
        "#2)\n",
        "\n",
        "Match_title = []\n",
        "Series = []\n",
        "Place = []\n",
        "Date = []\n",
        "Time = []\n",
        "\n",
        "def match():\n",
        "\tdriver.get('https://www.bcci.tv/')\n",
        "\n",
        "\thtml = driver.page_source\n",
        "\tsoup = BeautifulSoup(html, 'lxml')\n",
        "\tfix = soup.find('div', class_=\"drop-down__options\")\n",
        "\tfix_op = fix.find('a', class_=\"navigation__link\")\n",
        "\tfix_link = 'https://www.bcci.tv' + fix_op['href']\n",
        "\n",
        "\tdriver.get(fix_link)\n",
        "\ttime.sleep(5)\n",
        "\n",
        "\thtml = driver.page_source\n",
        "\n",
        "\tsoup = BeautifulSoup(html, 'lxml')\n",
        "\n",
        "\ttable = soup.find('div', class_=\"js-list\")\n",
        "\n",
        "\tcards = soup.find_all('div', class_=\"fixture__info\")\n",
        "\n",
        "\tfor i in cards:\n",
        "\t\tn = i.find('strong', class_=\"fixture__name\").text\n",
        "\t\tMatch_title.append(n)\n",
        "\n",
        "\t\tdt = i.find('span', class_=\"fixture__datetime tablet-only\")\n",
        "\t\t\n",
        "\t\td = dt.find('strong').text\n",
        "\t\tDate.append(d)\n",
        "\n",
        "\t\tt = dt.text.strip(d)\n",
        "\t\tTime.append(t)\n",
        "\n",
        "\t\tp = i.find('p', class_=\"fixture__additional-info\")\n",
        "\t\tpl = p.find('span').text\n",
        "\t\tPlace.append(pl)\n",
        "\t\t\n",
        "\t\ts = i.find('div', class_=\"fixture__format-strip\").text\n",
        "\t\tSeries.append(s)\n",
        "\n",
        "\tdf = pd.DataFrame({})\n",
        "\tdf['Match_title'] = Match_title \n",
        "\tdf['Series'] = Series\n",
        "\tdf['Place'] = Place\n",
        "\tdf['Date'] = Date\n",
        "\tdf['Time'] = Time\n",
        "\tdf.to_csv('bcci fixtures 2021')\n",
        "\ttime.sleep(5)\n",
        "\tdriver.quit()\n",
        "\n",
        "match()\n",
        "\n",
        "#3)\n",
        "\n",
        "Exception_Name = []\n",
        "Discription = []\n",
        "\n",
        "def gur():\n",
        "\tdriver.get('https://www.guru99.com/')\n",
        "\n",
        "\tb = driver.find_elements_by_xpath('//div[@class=\"canvas-middle\"]')\n",
        "\tsel = b[18]\n",
        "\tsel.click()\n",
        "\n",
        "\ttry:\n",
        "\t\tclose = driver.find_element_by_xpath('//*[@id=\"cbox\"]/div/div/div/div/div[1]')\n",
        "\t\tclose.click()\n",
        "\texcept:\n",
        "\t\tpass\n",
        "\n",
        "\texp = driver.find_elements_by_xpath('//td[@class=\"responsivetable\"]')\n",
        "\ta = exp[68]\n",
        "\ta.click()\n",
        "\n",
        "\ttime.sleep(3)\n",
        "\n",
        "\thtml = driver.page_source\n",
        "\tsoup = BeautifulSoup(html, 'lxml')\n",
        "\n",
        "\ttable = soup.find('table', class_='table')\n",
        "\tcol = table.find_all('tr')\n",
        "\tfor i in col:\n",
        "\t\talp = i.find_all('td')\n",
        "\t\t\n",
        "\t\ta = alp[0].text\n",
        "\t\tException_Name.append(a)\n",
        "\t\t\n",
        "\t\tb = alp[1].text\n",
        "\t\tDiscription.append(b)\n",
        "\n",
        "\tdf = pd.DataFrame({})\n",
        "\tdf['Exception_Name'] = Exception_Name\n",
        "\tdf['Description'] = Discription\n",
        "\tdf.to_csv('guru99')\n",
        "\ttime.sleep(5)\n",
        "\tdriver.quit()\n",
        "\n",
        "gur()\n",
        "\n",
        "#4)\n",
        "\n",
        "Rank = []\n",
        "State = []\n",
        "GSDP_at_current_price_19 = []\n",
        "GSDP_at_current_price_18 = []\n",
        "Share_18 = []\n",
        "GDP = []\n",
        "\n",
        "def stat():\n",
        "\tbase_url = 'http://statisticstimes.com/'\n",
        "\tdriver.get(base_url)\n",
        "\n",
        "\thtml = driver.page_source\n",
        "\tsoup = BeautifulSoup(html, 'lxml')\n",
        "\tdrpdn = soup.find_all('div', class_=\"dropdown-content\")\n",
        "\ta = drpdn[1]\n",
        "\tab = a.find_all('a')\n",
        "\tind = ab[2]\n",
        "\turl = base_url + ind['href']\n",
        "\n",
        "\tdriver.get(url)\n",
        "\n",
        "\tquat = driver.find_element(By.XPATH, '/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
        "\tquat.click()\n",
        "\n",
        "\ttime.sleep(3)\n",
        "\n",
        "\thtml = driver.page_source\n",
        "\tsoup = BeautifulSoup(html, 'lxml')\n",
        "\n",
        "\ttable = soup.find('table', id=\"table_id\")\n",
        "\tdata = table.find('tbody')\n",
        "\t\n",
        "\tcards = data.find_all('tr')\n",
        "\tfor i in cards:\n",
        "\t\tblock = i.find_all('td')\n",
        "\t\t\n",
        "\t\tr = block[0].text\n",
        "\t\tRank.append(r)\n",
        "\n",
        "\t\tn = block[1].text\n",
        "\t\tState.append(n)\n",
        "\n",
        "\t\tl = block[2].text\n",
        "\t\tGSDP_at_current_price_19.append(l)\n",
        "\n",
        "\t\tm = block[3].text\n",
        "\t\tGSDP_at_current_price_18.append(m)\n",
        "\n",
        "\t\ts = block[4].text\n",
        "\t\tShare_18.append(s)\n",
        "\n",
        "\t\tg = block[5].text\n",
        "\t\tGDP.append(g)\n",
        "\n",
        "\tdf = pd.DataFrame({})\n",
        "\tdf['Rank'] = Rank\n",
        "\tdf['State'] = State\n",
        "\tdf['GSDP_at_current_price_19-20'] = GSDP_at_current_price_19\n",
        "\tdf['GSDP_at_current_price_18-19'] = GSDP_at_current_price_18\n",
        "\tdf['Share_18-19'] = Share_18\n",
        "\tdf['GDP'] = GDP\n",
        "\tdf.to_csv('statistic times')\n",
        "\n",
        "\ttime.sleep(5)\n",
        "\tdriver.quit()\n",
        "\n",
        "\n",
        "stat()\n",
        "\n",
        "#5)\n",
        "\n",
        "Repository_title = []\n",
        "Repository_description = []\n",
        "Contributors_count = []\n",
        "Language_used = []\n",
        "Repository_url = []\n",
        "\n",
        "def git():\n",
        "\tbase_url = 'https://github.com'\n",
        "\t# driver.get(base_url)\n",
        "\n",
        "\t# html = driver.page_source\n",
        "\t# soup = BeautifulSoup(html, 'lxml')\n",
        "\t# con = soup.find_all('div', class_=\"dropdown-menu\")\n",
        "\t# tre = con[1]\n",
        "\n",
        "\t# e = tre.find_all('li', class_=\"edge-item-fix\")\n",
        "\t# ex = e[3]\n",
        "\t# exp = ex.find('a')\n",
        "\t# trending_url = (base_url+exp['href'])\n",
        "\n",
        "\tdriver.get('https://github.com/trending')\n",
        "\n",
        "\tcell = driver.find_element_by_xpath('/html/body/div[4]/main/div[3]')\n",
        "\tblock = cell.find_elements_by_xpath('/article[@class=\"\"]')\n",
        "\n",
        "\n",
        "\n",
        "\t# html = driver.page_source\n",
        "\t# soup = BeautifulSoup(html, 'lxml')\n",
        "\n",
        "\t# con = soup.find_all('div', class_=\"container-lg\")\n",
        "\t# cell = con[3]\n",
        "\n",
        "\t# data = cell.find_all('article', class_=\"Box-row\")\n",
        "\t# for i in data:\n",
        "\t# \tn = i.find('h1', class_=\"h3\").find('a')\n",
        "\t# \tRepository_title.append(n['href'].strip('/'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\ttime.sleep(5)\n",
        "\tdriver.quit()\n",
        "git()\n",
        "\n",
        "#6)\n",
        "\n",
        "Song_name = []\n",
        "Artist_name = []\n",
        "Last_week_rank = []\n",
        "Peak_rank = []\n",
        "Weeks_on_board = []\n",
        "\n",
        "def hot():\n",
        "\tdriver.get('https://www.billboard.com/')\n",
        "\n",
        "\ttime.sleep(3)\n",
        "\n",
        "\th = driver.find_elements_by_class_name('header__subnav__link')\n",
        "\thot100 = h[2]\n",
        "\thot100.click()\n",
        "\n",
        "\ttime.sleep(3)\n",
        "\n",
        "\thtml = driver.page_source\n",
        "\tsoup = BeautifulSoup(html, 'lxml')\n",
        "\n",
        "\ttable = soup.find('div', class_=\"chart-list__wrapper\")\n",
        "\tblocks = table.find_all('li', class_=\"chart-list__element\")\n",
        "\tfor i in blocks:\n",
        "\t\tn = i.find('span', class_=\"chart-element__information__song\").text\n",
        "\t\tSong_name.append(n)\n",
        "\n",
        "\t\ta = i.find('span', class_=\"chart-element__information__artist\").text\n",
        "\t\tArtist_name.append(a)\n",
        "\n",
        "\t\td = i.find_all('span', class_=\"chart-element__meta\")\n",
        "\t\tlw = d[0].text\n",
        "\t\tLast_week_rank.append(lw)\n",
        "\n",
        "\t\tpk = d[1].text\n",
        "\t\tPeak_rank.append(pk)\n",
        "\n",
        "\t\twks = d[2].text\n",
        "\t\tWeeks_on_board.append(wks)\n",
        "\n",
        "\ttime.sleep(5)\n",
        "\tdriver.quit()\n",
        "\n",
        "\tdf = pd.DataFrame({})\n",
        "\tdf['Song_name'] = Song_name\n",
        "\tdf['Artist_name'] = Artist_name\n",
        "\tdf['Last_week_rank'] = Last_week_rank\n",
        "\tdf['Peak_rank'] = Peak_rank\n",
        "\tdf['Weeks_on_board'] = Weeks_on_board\n",
        "\n",
        "\tdf.to_csv('hot 100 billboard')\n",
        "hot()\n",
        "\n",
        "#7)\n",
        "\n",
        "Name = []\n",
        "Designation = []\n",
        "Company = []\n",
        "Skills = []\n",
        "Location = []\n",
        "\n",
        "def nuak():\n",
        "\tdriver.get('https://www.naukri.com/')\n",
        "\n",
        "\ttime.sleep(5)\n",
        "\n",
        "\ttry:\n",
        "\t\tgeo_req = driver.find_element_by_id('geoLocPopUp')\n",
        "\t\tlater = geo_req.find_element_by_class_name('later')\n",
        "\t\tlater.click()\n",
        "\texcept:\n",
        "\t\tpass\n",
        "\n",
        "\n",
        "\tops = driver.find_elements_by_class_name('mTxt')\n",
        "\trec = ops[1]\n",
        "\trec.click()\n",
        "\n",
        "\ttime.sleep(3)\n",
        "\n",
        "\twindow_before = driver.window_handles[1]\n",
        "\tdriver.switch_to.window(window_before)\n",
        "\n",
        "\ttime.sleep(3)\n",
        "\n",
        "\tjob = driver.find_element_by_class_name('sugInp')\n",
        "\tjob.send_keys('Data science')\n",
        "\tjob.send_keys(Keys.RETURN)\n",
        "\ttime.sleep(5)\n",
        "\n",
        "\thtml = driver.page_source\n",
        "\tsoup = BeautifulSoup(html, 'lxml')\n",
        "\n",
        "\ttable = soup.find('div', id=\"tabP-1\")\n",
        "\tcards = table.find_all('div', class_=\"recSec\")\n",
        "\tfor i in cards:\n",
        "\t\tn = i.find('span', class_=\"fl ellipsis\").text\n",
        "\t\tName.append(n)\n",
        "\n",
        "\t\td = i.find('span', class_=\"ellipsis clr\").text\n",
        "\t\tDesignation.append(d)\n",
        "\n",
        "\t\tc = i.find_all('a', class_=\"ellipsis\")\n",
        "\t\tcom = c[1].text\n",
        "\t\tCompany.append(com)\n",
        "\n",
        "\t\tl = i.find_all('span')\n",
        "\t\tloc = l[2].text\n",
        "\t\tLocation.append(loc)\n",
        "\n",
        "\t\ts = i.find('div', class_=\"hireSec highlightable\").text\n",
        "\t\tSkills.append(s)\n",
        "\n",
        "\ttime.sleep(10)\n",
        "\tdriver.quit()\n",
        "\n",
        "\tdf = pd.DataFrame({})\n",
        "\tdf['Name'] = Name\n",
        "\tdf['Designation'] = Designation\n",
        "\tdf['Company'] = Company\n",
        "\tdf['Location'] = Location\n",
        "\tdf['Skills'] = Skills\n",
        "\n",
        "\tdf.to_csv('naukri.com')\n",
        "nuak()\n",
        "\n",
        "#8)\n",
        "\n",
        "Book_name = []\n",
        "Author_name = []\n",
        "Volumes_sold = []\n",
        "Publisher = []\n",
        "Genre = []\n",
        "\n",
        "\n",
        "def guard():\n",
        "\n",
        "\tdriver.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare')\n",
        "\n",
        "\thtml = driver.page_source\n",
        "\tsoup = BeautifulSoup(html, 'lxml')\n",
        "\n",
        "\ttable = soup.find('div', class_=\"embed block\")\n",
        "\tdata = table.find('tbody')\n",
        "\tcards = data.find_all('tr')\n",
        "\tfor i in cards:\n",
        "\t\tb = i.find_all('td')\n",
        "\t\t\n",
        "\t\tb_name = b[1].text\n",
        "\t\tBook_name.append(b_name)\n",
        "\t\t\n",
        "\t\ta = b[2].text\n",
        "\t\tAuthor_name.append(a)\n",
        "\n",
        "\t\tv = b[3].text\n",
        "\t\tVolumes_sold.append(v)\n",
        "\n",
        "\t\tp = b[4].text\n",
        "\t\tPublisher.append(p)\n",
        "\n",
        "\t\tg = b[5].text\t\t\n",
        "\t\tGenre.append(g)\n",
        "\n",
        "\tdf = pd.DataFrame({})\n",
        "\tdf['Book_name'] = Book_name\n",
        "\tdf['Author_name'] = Author_name\n",
        "\tdf['Volumes_sold'] = Volumes_sold\n",
        "\tdf['Publisher'] = Publisher\n",
        "\tdf['Genre'] = Genre\n",
        "\n",
        "\tdf.to_csv('highest sellng novels')\n",
        "\ttime.sleep(5)\n",
        "\tdriver.quit()\n",
        "\n",
        "guard()\n",
        "\n",
        "#9)\n",
        "\n",
        "Name = []\n",
        "Year_span = []\n",
        "Genre = []\n",
        "Run_time = []\n",
        "Ratings = []\n",
        "Votes = []\n",
        "\n",
        "\n",
        "def imdb():\n",
        "\tdriver.get('https://www.imdb.com/list/ls095964455/')\n",
        "\n",
        "\thtml = driver.page_source\n",
        "\tsoup = BeautifulSoup(html, 'lxml')\n",
        "\n",
        "\ttable = soup.find('div', class_=\"lister list detail sub-list\")\n",
        "\tdata = table.find('div', class_=\"lister-list\")\n",
        "\tcards = data.find_all('div', class_=\"lister-item mode-detail\")\n",
        "\tfor i in cards:\n",
        "\t\tn = i.find('h3').find('a').text\n",
        "\t\tName.append(n)\n",
        "\n",
        "\t\ty = i.find('h3').find_all('span')\n",
        "\t\tyear = y[1].text\n",
        "\t\tYear_span.append(year)\n",
        "\n",
        "\t\tg = i.find('p').find('span', class_=\"genre\").text\n",
        "\t\tGenre.append(g)\n",
        "\n",
        "\t\trt = i.find('p').find('span', class_=\"runtime\").text\n",
        "\t\tRun_time.append(rt)\n",
        "\n",
        "\t\trat = i.find('div', class_=\"ipl-rating-widget\").find('span', class_=\"ipl-rating-star__rating\").text\n",
        "\t\tRatings.append(rat)\n",
        "\n",
        "\t\tv = i.find_all('p', class_=\"text-muted\")\n",
        "\t\tvotes = v[2]\n",
        "\t\tvn = votes.find_all('span')\n",
        "\t\tvns = vn[1].text\n",
        "\t\tVotes.append(vns)\n",
        "\n",
        "\tdf = pd.DataFrame({})\n",
        "\tdf['Name'] = Name\n",
        "\tdf['Year_span'] = Year_span\n",
        "\tdf['Genre'] = Genre \n",
        "\tdf['Run_time'] = Run_time\n",
        "\tdf['Ratings'] = Ratings\n",
        "\tdf['Votes'] = Votes\n",
        "\n",
        "\n",
        "\tdf.to_csv('imdb top 100 series')\n",
        "\ttime.sleep(5)\n",
        "\tdriver.quit()\n",
        "\n",
        "imdb()\n",
        "\n",
        "#10)\n",
        "\n",
        "Dataset_name = []\n",
        "Data_type = []\n",
        "Task = []\n",
        "Attribute_type = []\n",
        "No_of_instances = []\n",
        "No_of_attribute = []\n",
        "Year = []\n",
        "\n",
        "\n",
        "def lol():\n",
        "\tdriver.get('https://archive.ics.uci.edu/ml/index.php')\n",
        "\n",
        "\tds = driver.find_element(By.XPATH, '/html/body/table[1]/tbody/tr/td[2]/span[2]/a/font/b')\n",
        "\tds.click()\n",
        "\n",
        "\ttime.sleep(3)\n",
        "\n",
        "\thtml = driver.page_source\n",
        "\tsoup = BeautifulSoup(html, 'lxml')\n",
        "\n",
        "\tdata = soup.find_all('tbody')\n",
        "\tpanel = data[5]\n",
        "\tcards = panel.find_all('tr')\n",
        "\tcards.remove(cards[0])\n",
        "\n",
        "\tlocal_list = []\n",
        "\n",
        "\tfor i in cards:\n",
        "\t\tdata = i.find_all('td')\n",
        "\t\tfor i in data:\n",
        "\t\t\tlocal_list.append(i.text.strip(' '))\n",
        "\n",
        "\tfor i in range(0, 6468, 11):\n",
        "\t\tDataset_name.append(local_list[i])\n",
        "\n",
        "\tfor i in range(3, 6468, 11):\n",
        "\t\tData_type.append(local_list[i])\n",
        "\n",
        "\tfor i in range(4, 6468, 11):\n",
        "\t\tTask.append(local_list[i])\n",
        "\n",
        "\tfor i in range(5, 6468, 11):\n",
        "\t\tAttribute_type.append(local_list[i])\n",
        "\n",
        "\tfor i in range(6, 6468, 11):\n",
        "\t\tNo_of_instances.append(local_list[i])\n",
        "\n",
        "\tfor i in range(7, 6468, 11):\n",
        "\t\tNo_of_attribute.append(local_list[i])\n",
        "\n",
        "\tdf = pd.DataFrame({})\n",
        "\tdf['Dataset_name'] = Dataset_name\n",
        "\tdf['Data_type'] = Data_type\n",
        "\tdf['Task'] = Task\n",
        "\tdf['Attribute_type'] = Attribute_type\n",
        "\tdf['No_of_instances'] = No_of_instances\n",
        "\tdf['No_of_attribute'] = No_of_attribute\n",
        "\n",
        "\tdf.to_csv('datasets')\n",
        "\ttime.sleep(5)\n",
        "\tdriver.quit()\n",
        "lol()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}